<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Segmentation | Cynicsss</title>

<meta name="keywords" content="" />
<meta name="description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod">
<meta name="author" content="Theme PaperMod">
<link rel="canonical" href="https://cynicsss.github.io/categories/segmentation/" />
<link href="https://cynicsss.github.io/assets/css/stylesheet.min.a6f0d5df794729458ca1bb78b2bf3b208731513d810461a864ce51071e20ea48.css" integrity="sha256-pvDV33lHKUWMobt4sr87IIcxUT2BBGGoZM5RBx4g6kg=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://cynicsss.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://cynicsss.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://cynicsss.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://cynicsss.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://cynicsss.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.79.1" />
<link rel="alternate" type="application/rss&#43;xml" href="https://cynicsss.github.io/categories/segmentation/index.xml">


<meta property="og:title" content="Segmentation" />
<meta property="og:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://cynicsss.github.io/categories/segmentation/" />
<meta property="og:updated_time" content="2020-12-31T00:00:00+00:00" /><meta property="og:site_name" content="Cynicsss" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Segmentation"/>
<meta name="twitter:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"/>



</head>

<body class="list">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        .theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://cynicsss.github.io/" accesskey="h" title="Cynicsss (Alt + H)">Cynicsss</a>
            <span class="logo-switches">
                <span class="theme-toggle" title="(Alt + T)">
                    <a id="theme-toggle" accesskey="t">
                        <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                        </svg>
                        <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"></circle>
                            <line x1="12" y1="1" x2="12" y2="3"></line>
                            <line x1="12" y1="21" x2="12" y2="23"></line>
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                            <line x1="1" y1="12" x2="3" y2="12"></line>
                            <line x1="21" y1="12" x2="23" y2="12"></line>
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                        </svg>
                    </a>
                </span>
                
            </span>
        </div>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://cynicsss.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://cynicsss.github.io/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://cynicsss.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li></ul>
    </nav>
</header>

    <main class="main"> 
<header class="page-header">
  <h1>Segmentation</h1>
</header>



<article class="post-entry tag-entry"> 

  <header class="entry-header">
    <h2>
      显著性检测、语义分割与图像抠图的区别
    </h2>
  </header>
  <section class="entry-content">
    <p>那天看到有关于Image Matting的论文，感觉就是二分类语义分割————显著性检测的样子，但是查了下才发现不一样…
...</p>
  </section>
  <footer class="entry-footer">

December 31, 2020&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cynicsss
</footer>
  <a class="entry-link" aria-label="post link to 显著性检测、语义分割与图像抠图的区别" href="https://cynicsss.github.io/posts/%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E6%B5%8B%E5%88%86%E5%89%B2%E6%8A%A0%E5%9B%BE/"></a>
</article>
<article class="post-entry tag-entry"> 

  <header class="entry-header">
    <h2>
      车道线检测LaneDetection
    </h2>
  </header>
  <section class="entry-content">
    <p>车道线检测方浩AAAI2021新SOTA-RESA分享总结
车道线检测LaneDetection 车道线检测是自动驾驶领域里环境感知环节重要的一部分，之前在商汤实习有接触到项目中的轻量级车道线检测是使用Gridding方法，但没有全面了解过车道线检测，借此次干货分享学习一下~
1.Background 车道线检测顾名思义如图中所示 检测并预测补全所输入的RGB图像中的K条车道线，每条车道线互相独立类别不同。 上图所示为自动驾驶的实现思路，我们首先通过各种不同的sensors获取周围环境的数据(RGB或RGBD图像，三维点云等)，再使用环境感知算法分析数据，得到感知定位结果并送入Planning规划环节。在Planning环节中通过对感知的环境结果进行分析，做出行为路线等规划，做出决策，车辆控制单元接收到决策，从硬件上操控车辆实现各种驾驶操作。
车道线检测作为环境感知中非常重要的一部分，对于车辆驾驶决策有以下几点作用：
 判断当前车辆所在车道，并保持车辆在车道内行驶防止偏向变道。 变道时判断变道行驶角度，并决定何时变道结束。 判断其他车辆所在车道，并预测其他车辆驾驶可能驾驶轨迹。  车道线检测的定义：
输出有多种形式，根据不同方法有不同输出，可以为instances的mask，我直接输出检测出的mask，也可以为一些点，将这些点连为直线或曲线便为车道线，也可为一些参数，通过这些参数拟合曲线。
车道线检测主要的难点：
 遮挡严重，线为一段一段的而我们需要补全，同时可能路面有磨损 有些地方车道线看不清 线又细又长，不想目标检测 语义分割，我们有大块物体可供检测分割，车道线是细长的，在图像中比例不大。 实时性，因为我们需要在自动驾驶中使用，所以需要实时性。  2.Related Work 车道线检测的工作主要有下面几个方向：
 Traditional methods Semantic / instance segmentation-based New formulation (gridding, polynomial, anchor-based, etc.)  传统方法，语义/实例分割方法以及一些比较新奇的思路。传统方法实用性较差，目前大部分方向都集中于第2、3类。 97年的传统方法，首先将RGB转为灰度图，再做高斯模糊，然后用Canny算子检测边缘部分，霍夫变换检测出图像中的直线。所得到的直线并不知道直线的起点与终点所以就如图所示两条直线，所适用场景比较局限。
两个分支，一个学习pixel embedding一个学习mask，将预测出的线的位置乘以embedding，再用聚类分出来不同的线。此方法思路比较简单，但依赖于聚类，也同样不知道车道线起始与终点，效果并不是很好。
基于语义分割的很直接的方法，K条线则为K个类别，每条线对应一个类别，最终输出一张含有多个类别的mask，则输出了多条线。本篇工作还用了类似RNN方法，把信息在H与W维度上进行传递。
后续好多基于分割的方法都致力于将模型轻量化，如上图，第一个方法使用蒸馏，第二个方法使用NAS。 下面这种方法就是Gridding，将图像分成多个小块，我个人理解就是将图像进行下采样，通过各种方式预测出来的grids作为点，最后连接成为车道线。还有其他等等新奇的方法……
3.RESA 论文地址：RESA
Intuation： 作者一开始的想法跟我一样….：车道线检测看起来就是语义分割，那么我们直接用语义分割当中的算法训练不就可以了吗？作者进行了实验(deeplab)发现语义分割算法得到效果很差，于是有了以下分析：
Why classical segmantic segmentation does not work?
 Severe occlusion &amp; ambiguous lanes Sparse supervisory signals inherent in lane annotations (thin and long)  主要来说就是车道线这种特殊case的特殊性：跟语义分割不同，车道线所占区域很窄很小，就如同语义分割中电线杆类别，很容易误检错检，与此同时语义分割是所见即所得，但是车道线因为有虚线所以还需要算法进行自动补全，这是语义分割算法所缺失的 (本次分享及作者的论文其实感觉主要就是解决这个问题的，但是感觉他的特征传递方法work的原因并不是作者想的那样)。...</p>
  </section>
  <footer class="entry-footer">

December 26, 2020&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cynicsss
</footer>
  <a class="entry-link" aria-label="post link to 车道线检测LaneDetection" href="https://cynicsss.github.io/posts/%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8Blanedetection/"></a>
</article>
<article class="post-entry tag-entry"> 

  <header class="entry-header">
    <h2>
      AGSS-VOS
    </h2>
  </header>
  <section class="entry-content">
    <p>此篇文章为iccv2019中关于视频分割的一篇文章，主要针对多物体进行视频object分割，值得一读
...</p>
  </section>
  <footer class="entry-footer">

December 20, 2019&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cynicsss
</footer>
  <a class="entry-link" aria-label="post link to AGSS-VOS" href="https://cynicsss.github.io/posts/agss-vos/"></a>
</article>
<article class="post-entry tag-entry"> 

  <header class="entry-header">
    <h2>
      DANet-CCNet
    </h2>
  </header>
  <section class="entry-content">
    <p>两篇文章都是将self-attention机制应用到分割当中，扩大感受野。第二篇文章采用了更巧妙的方法来减少参数。
...</p>
  </section>
  <footer class="entry-footer">

November 20, 2019&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cynicsss
</footer>
  <a class="entry-link" aria-label="post link to DANet-CCNet" href="https://cynicsss.github.io/posts/danet-ccnet/danet-ccnet/"></a>
</article>
<article class="post-entry tag-entry"> 

  <header class="entry-header">
    <h2>
      EncNet
    </h2>
  </header>
  <section class="entry-content">
    <p>本文提出了上下文编码模块(Context Encoding Module)引入全局上下文信息(global contextual information)，用于捕获场景的上下文语义并选择性的突出与类别相关的特征图。 实验证明上下文编码模块能够显著的提升语义分割性能，在Pascal-Context上达到了51.7%mIoU, 在 PASCAL VOC 2012上达到了85.9% mIoU，单模型在ADE20K测试集上达到了0.5567。 此外,论文进一步讨论上下文编码模块在相对浅层的网络中提升特征表示的能力，在CIFAR-10数据集上基于14层的网络达到了3.45%的错误率，和比这个多10倍的层的网络有相当的表现。
EncNet introduction 扩张卷积存在的问题 先进的语义分割系统通常是基于FCN架构，采用的深度卷积神经网络受益于从不同图片中学习到的丰富的对象类别信息和场景语义。CNN通过堆叠带非线性激活和下采样的卷积层能够捕获带全局接受野的信息表示，为了克服下采样带来的空间分辨率损失，最近的工作使用扩张卷积策略从预训练模型上产生密集预测。然而，此策略依然会将像素从全局场景上下文相隔开，这会导致像素错误分类。
如下图，错误的将窗格分为门。
金字塔结构存在的问题 近期的工作使用基于金字塔多分辨率表示扩大接受野。例如，PSPNet采用的PSP模块将特征图池化为不同尺寸，再做联接上采样；DeepLab采用ASPP模块并行的使用大扩张率卷积扩大接受野。这些方法都有提升，但是这对上下文表示都不够明确，这出现了一个问题： 捕获上下文信息是否等同于增加接受野大小？
考虑到如下情况，在一个大型数据集上，如下图：
如果能够先捕获到图像上下文信息(例如这是卧室)，然后，这可以提供许多相关小型目标的信息(例如卧室里面有床、椅子等)。这可以动态的减少搜索区域可能。说白了，这就是加入一个场景的先验知识进去，这样对图片中像素分类更有目的性。依照这个思路，可以设计一种方法，充分利用场景上下文和存在类别概率的之间的强相关性，这样语义分割会就容易很多。 能否利用经典方法的上下文编码结合深度学习？ 最近有工作在CNN框架中推广传统编码器方法获得了极大的进步，在本文中，使用扩展编码层来捕获全局特征的统计信息用于理解上下文语义。
contribution 第一个贡献： 引入了上下文编码模块，该单元用于捕获全局场景上下文信息和选择性的突出与类别相关的特征图。 集成了语义编码损失(Semantic Encoding Loss,SE-loss)。 举例来讲，不考虑车辆出现在卧室的可能性，在现有标准的训练过程使用的是像素分割损失，这不强调场景的全局信息。引入语义编码损失(SE-loss)可进一步规范网络训练，让网络预测能够预测场景中对象类别的存在，强化网络学习上下文语义。 与逐像素的损失不同，SE-Loss对于大小不同的物体有相同的贡献，在实践中这能够改善识别小物体的表现。
第二个贡献： 设计了一个新的语义分割架构Context Encoding Network (EncNet)。如下图所示，EncNet通过上下文编码模块增强了预训练的ResNet：
Context Encoding： 对于预训练网络，使用编码层捕获特征图的统计信息作为全局上下文语义，将编码层的输出作为编码语义(encoded semantics)，为了使用上下文，预测了一组放缩因子(scaling factors)用于突出和类别相关的特征图。编码层学习带有上下文语义的固有字典，输出丰富上下文信息的残差编码。
Input feature: CXWXH —&gt;x={x1,x2,…,xN},N=H×W
Inherent codebook: D={d1,d2,…,dk}
Scaling factors: S={s1,s2,…,sk}
最后会输出k个残差编码，这样做的目的是什么呢？
通过将图像的HXW个C维特征，每一个都与语义词dk做差，然后和所有语义词做差的结果相加进行归一化，获得一个像素位置相对于某个语义词的信息eik，然后将这N个结果求和加在一块获得最终的ek，获得整张图像相对于第k个语义词的信息。
ek是C维的，最后将k个ek融合到一起，这里没有用concat，一方面concat包含了顺序信息，另一方面用加的方法节省了显存。这里加起来的含义是获得整张图像相对于K个语义词的全部信息 ，最后的e也是c维的。
Featuremap Attention： 为了使用编码层捕获的编码语义，预测一组特征图的放缩因子作为循环用于突出需要强调的类别。这样的方法受SE-Net等工作的启发，即考虑强调天空出现飞机，不强调出现车辆的可能性。
Semantic Encoding Loss： 使用Semantic Encoding Loss (SE-loss)在添加少量额外计算消耗的情况下强制网络理解全局语义信息。不同于逐像素损失，SE loss 对于大小不同的目标有相同的贡献，这能够提升小目标的检测性能。
实验结果 Results on PASCAL-Context： Results on ADE20K： Image Classification Results on CIFAR10： ...</p>
  </section>
  <footer class="entry-footer">

June 25, 2019&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cynicsss
</footer>
  <a class="entry-link" aria-label="post link to EncNet" href="https://cynicsss.github.io/posts/encnet/"></a>
</article>

    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://cynicsss.github.io/">Cynicsss</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<button class="top-link" id="top-link" type="button" aria-label="go to top" title="Go to Top (Alt + G)" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
        <path d="M12 6H0l6-6z" /></svg>
</button>



<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
    mybutton.onclick = function () {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
        window.location.hash = ''
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
